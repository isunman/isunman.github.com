<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"/>




  <link href="//fonts.googleapis.com/css?family=Lato:300,400,700,400italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">



<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=0.5.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="AI,思考," />





  <link rel="alternate" href="/atom.xml" title="太阳侠" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=0.5.0" />






<meta name="description" content="人工智能现在是常见词汇，大多数人可能觉得，它是学术话题，跟普通人关系不大。但是实际上，AI 突飞猛进，正在脱离实验室，进入日常生活。仅仅是现在的技术水平，就足以模糊现实与虚拟的界限，颠覆一般民众的认知。

（图1：2018年10月，世界第一幅 AI 生成的肖像画，拍卖成交价43.25万美元。）
为了让普通人了解 AI 的进展，谷歌的机器学习专家格里高利·萨普诺夫（Grigory Sapunov）写">
<meta property="og:type" content="article">
<meta property="og:title" content="你所不知道的 AI 进展">
<meta property="og:url" content="http://isunman.com/2019/10/29/AI-progress-you-do-not-know/index.html">
<meta property="og:site_name" content="太阳侠">
<meta property="og:description" content="人工智能现在是常见词汇，大多数人可能觉得，它是学术话题，跟普通人关系不大。但是实际上，AI 突飞猛进，正在脱离实验室，进入日常生活。仅仅是现在的技术水平，就足以模糊现实与虚拟的界限，颠覆一般民众的认知。

（图1：2018年10月，世界第一幅 AI 生成的肖像画，拍卖成交价43.25万美元。）
为了让普通人了解 AI 的进展，谷歌的机器学习专家格里高利·萨普诺夫（Grigory Sapunov）写">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102801.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102802.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102803.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102804.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102805.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102806.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102807.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102808.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102809.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102810.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102812.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102813.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102814.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102815.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102816.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102817.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102818.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102819.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102820.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102821.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102829.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102824.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102825.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102826.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102827.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102830.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102831.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102832.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102833.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102834.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102837.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102835.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102836.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102838.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102839.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102840.jpg">
<meta property="og:image" content="https://www.wangbase.com/blogimg/asset/201910/bg2019102841.jpg">
<meta property="og:updated_time" content="2019-10-29T04:41:38.531Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="你所不知道的 AI 进展">
<meta name="twitter:description" content="人工智能现在是常见词汇，大多数人可能觉得，它是学术话题，跟普通人关系不大。但是实际上，AI 突飞猛进，正在脱离实验室，进入日常生活。仅仅是现在的技术水平，就足以模糊现实与虚拟的界限，颠覆一般民众的认知。

（图1：2018年10月，世界第一幅 AI 生成的肖像画，拍卖成交价43.25万美元。）
为了让普通人了解 AI 的进展，谷歌的机器学习专家格里高利·萨普诺夫（Grigory Sapunov）写">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: undefined,
      author: '博主'
    }
  };
</script>

  <title> 你所不知道的 AI 进展 | 太阳侠 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  



  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?edc09d74f003ef7b14a37137efc44fd4";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>






  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">太阳侠</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">我是一颗恒星</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu ">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-home fa-fw"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-th fa-fw"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-archive fa-fw"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-tags fa-fw"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-user fa-fw"></i> <br />
            
            关于
          </a>
        </li>
      

      
      
      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                你所不知道的 AI 进展
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2019-10-29T12:41:38+08:00" content="2019-10-29">
              2019-10-29
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/未来探索/" itemprop="url" rel="index">
                    <span itemprop="name">未来探索</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>人工智能现在是常见词汇，大多数人可能觉得，它是学术话题，跟普通人关系不大。<br>但是实际上，AI 突飞猛进，正在脱离实验室，进入日常生活。仅仅是现在的技术水平，就足以模糊现实与虚拟的界限，颠覆一般民众的认知。</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102801.jpg" alt=""></p>
<p>（图1：2018年10月，世界第一幅 AI 生成的肖像画，<a href="https://www.christies.com/features/A-collaboration-between-two-artists-one-human-one-a-machine-9332-1.aspx" target="_blank" rel="external">拍卖</a>成交价43.25万美元。）</p>
<p>为了让普通人了解 AI 的进展，谷歌的机器学习专家格里高利·萨普诺夫（Grigory Sapunov）写了一篇通俗的<a href="https://blog.inten.to/welcome-to-the-simulation-dd0d8cb6534d" target="_blank" rel="external">科普文章</a>，介绍目前的技术成果。这盘文章非常精彩，有大量的图片，加上一些简单的解释，信息量很大，对于了解技术动态很有帮助。</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102802.jpg" alt=""></p>
<p>（图2：谷歌的机器学习专家格里高利·萨普诺夫）<br>下面就是那篇文章的翻译，比较长，图片很多，但是值得耐心读完。我保证，有些内容一定会让你感到吃惊。</p>
<h2 id="一、图像处理"><a href="#一、图像处理" class="headerlink" title="一、图像处理"></a>一、图像处理</h2><p>人工智能最早是从图像处理开始的。图像处理是一种常见任务，智能要求比较高，需要使用 PhotoShop 之类的软件人工编辑，一般的算法解决不了。</p>
<h3 id="1-1-对象补全"><a href="#1-1-对象补全" class="headerlink" title="1.1 对象补全"></a>1.1 对象补全</h3><p>2017年，日本科学家提出了一种<a href="https://web.archive.org/web/20191016060740/http://iizuka.cs.tsukuba.ac.jp/projects/completion/en/" target="_blank" rel="external">图像的对象补全模型</a>。经过训练，模型可以补全图片上缺失的部分。</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102803.jpg" alt=""></p>
<p>（图3：图像的对象补全模型）<br>上图中，左边是原始图片，然后把中间的花盆涂掉，输入模型。模型会自动补全缺失的部分（右图），由于它不知道，那里有一个花盆，所以只会根据没有涂掉的部分，补上地板和扶手。<br>下面是更多这样的例子。涂掉的部分，模型都会补上，哪怕它根本不知道，那里原来是什么。</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102804.jpg" alt=""></p>
<p>（图4：图像的对象补全示例）<br>Nvidia 公司将这个模型做成了产品，放在网上。你可以到<a href="https://www.nvidia.com/research/inpainting/" target="_blank" rel="external">它的网站</a>，上传一张图片，然后涂掉一些部分，让网站替你补全。</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102805.jpg" alt=""></p>
<p>（图5：涂掉沙发旁边的茶几）<br>有的<a href="https://www.slashgear.com/adobes-entry-level-photoshop-elements-gets-new-ai-powered-tools-04594215/" target="_blank" rel="external">图像软件</a>已经应用这项技术，去除人像脸上的斑点。</p>
<h3 id="1-2-背景处理"><a href="#1-2-背景处理" class="headerlink" title="1.2 背景处理"></a>1.2 背景处理</h3><p>背景处理指的是，将前景物体从图片分离出来，再对背景进行加工。目前，已经有<a href="https://towardsdatascience.com/background-removal-with-deep-learning-c4f2104b3157" target="_blank" rel="external">很好的智能算法</a>可以去除图片背景。</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102806.jpg" alt=""><br>（图6：图片的背景去除）<br>在模型内部，图片会转成像素的色块。下图的浅紫色块就是前景物体，然后再把这些像素提取出来。</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102807.jpg" alt=""><br>（图7：背景去除模型）<br>这个模型也已经做成了<a href="https://www.remove.bg/" target="_blank" rel="external">线上服务</a>，大家可以上传图片感受一下它的效果。<br>既然可以去除背景，那当然就可以<a href="https://arxiv.org/abs/1703.03872" target="_blank" rel="external">更改背景</a>，为图片合成打开方便之门。</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102808.jpg" alt=""><br>（图8：更改图片背景）</p>
<h3 id="1-3-样式转换"><a href="#1-3-样式转换" class="headerlink" title="1.3 样式转换"></a>1.3 样式转换</h3><p>人工智能还能够<a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf" target="_blank" rel="external">识别</a>图片的风格样式（即像素的变化规律），将其套用在另一张图片。</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102809.jpg" alt=""><br>（图9：原始图片）<br>上图是两张原始图片，第一张是梵高的名画《星夜》，第二张是普通的风景照。模型可以提取第一张图片的风格，将其套用在第二张图片。</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102810.jpg" alt=""><br>（图10：套用梵高的《星夜》风格）<br>其他名画的风格，同样可以套用。</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102812.jpg" alt=""><br><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102813.jpg" alt=""><br>（图11：图像的风格转换）</p>
<h3 id="1-4-图像着色"><a href="#1-4-图像着色" class="headerlink" title="1.4 图像着色"></a>1.4 图像着色</h3><p>一旦识别出图片中的物体，模型就可以统计不同物体的像素颜色规律，然后就能推断黑白照片可能的颜色，从而实现<a href="https://arxiv.org/abs/1603.06668" target="_blank" rel="external">照片着色</a>。</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102814.jpg" alt=""><br>（图12：黑白照片的着色）<br>网上也有免费的<a href="https://colorize.cc/" target="_blank" rel="external">着色服务</a>，大家可以体验。</p>
<h2 id="二、GAN-方法"><a href="#二、GAN-方法" class="headerlink" title="二、GAN 方法"></a>二、GAN 方法</h2><h3 id="2-1-简介"><a href="#2-1-简介" class="headerlink" title="2.1 简介"></a>2.1 简介</h3><p>GAN 是”生成对抗网络”（Generative Adversarial Networks）的缩写，它是一种革命性的提升人工智能模型效果、生成虚拟图像的方法。<br>原理很简单，就是两个神经网络互相对抗。一个神经网络负责生成虚拟图像，另一个神经网络负责鉴定假图像。理论上，如果 GAN 训练成功，那么生成的假图像与真图像将无法区分。2014年，这种方法提出以后，快速发展，目前效果已经可以乱真。</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102815.jpg" alt=""><br>（图13：GAN 的改进速度）<br>上图是过去几年，GAN 生成的虚拟人像。可以发现，每过一年，图片越来越大，细节越来越丰富，越发接近真实人像。它的工作方法也是如此，第一步生成一张低分辨率图片，然后慢慢放大，依次修改每一个像素，确定该像素怎样才能最大概率通过鉴定器。<br>GAN 不仅能生成虚拟图像，还能生成音频、文本，甚至是化合物分子。AI 模型可能创造出来的任何东西，都能使用 GAN 提升效果。GitHub 有一个<a href="https://github.com/hindupuravinash/the-gan-zoo" target="_blank" rel="external">仓库</a>，专门收集不同用途的 GAN，目前已经有500多种模型。</p>
<h3 id="2-2-StyleGAN"><a href="#2-2-StyleGAN" class="headerlink" title="2.2 StyleGAN"></a>2.2 StyleGAN</h3><p>目前，生成虚拟人像效果最好的模型是 Nvidia 公司的 <a href="https://arxiv.org/abs/1812.04948" target="_blank" rel="external">StyleGAN</a>。下面两张头像，你能分辨哪张是虚拟的，哪张是真实的吗？</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102816.jpg" alt=""><br>（图14：GAN 虚拟人像）<br>这是网站截图，你可以去<a href="http://www.whichfaceisreal.com/" target="_blank" rel="external">那个网站</a>试试看，能猜对多少张。需要提醒的是，这是2018年底的模型产物，随着模型进化，迟早将无法分辨真假。<br>GAN 不仅能生成人像，实际上可以生成任何图像。下面是 <a href="https://arxiv.org/abs/1809.11096" target="_blank" rel="external">BigGAN</a> 模型生成的各种图像，图片里的东西都是不存在的。</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102817.jpg" alt=""><br>（图15：BigGAN 模型生成的虚拟图像）</p>
<h3 id="2-3-图像翻译"><a href="#2-3-图像翻译" class="headerlink" title="2.3 图像翻译"></a>2.3 图像翻译</h3><p>一种图像通过 GAN 转变为另一种图像，称为图像翻译。空拍照片变成地图、黑白照片变成彩色照片，都是图像翻译的例子。<br><a href="https://github.com/phillipi/pix2pix" target="_blank" rel="external">pix2pix</a> 是图像翻译的开源工具，它可以让黑夜变成白天，示意图变成实物图。</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102818.jpg" alt=""><br>（图16：图像翻译）<br>也可以让春天变成夏天，晴天变成雨天。</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102819.jpg" alt=""><br>（图17：图像翻译）<br>图像翻译的难点在于，它需要有成对的示例（源图像和相应的目标图像），告诉模型应该怎么翻译，这些示例可能很难创建。但是反过来，只要有配对的示例，就可以翻译图像，不管这种翻译是否合理。下面是两只小猫翻译成对应的豹子、狮子和老虎。</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102820.jpg" alt=""><br>（图18：图像翻译）<br><a href="https://github.com/junyanz/CycleGAN" target="_blank" rel="external">CycleGAN</a> 模型还支持跨域翻译，将照片翻译成油画，斑马翻译成马。</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102821.jpg" alt=""><br>（图19：图像翻译）<br>Nvidia 开发了一个 <a href="http://nvidia-research-mingyuliu.com/gaugan" target="_blank" rel="external">GauGAN</a> 软件，可以在线试玩。用户只需手绘一个示意图，软件就能生成一张对应的风景照片。</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102829.jpg" alt=""><br>（图20：GauGAN 将示意图变成照片）</p>
<h3 id="2-4-人像翻译"><a href="#2-4-人像翻译" class="headerlink" title="2.4 人像翻译"></a>2.4 人像翻译</h3><p>图像翻译用于人像，就是人像翻译。<a href="https://github.com/yunjey/StarGAN" target="_blank" rel="external">StarGAN</a> 模型可以翻译面部属性，比如头发的颜色、性别、肤色等。</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102824.jpg" alt=""><br>（图21：脸部属性的改变）<br>还可以把其他人的表情移植到你的脸上，下图分别是愤怒、快乐、恐惧的表情翻译。</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102825.jpg" alt=""><br>（图22：表情的改变）<br><a href="https://github.com/run-youngjoo/SC-FEGAN" target="_blank" rel="external">SC-FEGAN</a> 是人像翻译的开源软件，可以让你编辑人像，比如加上刘海，去除墨镜等等。</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102826.jpg" alt=""><br><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102827.jpg" alt=""><br>（图23：人像编辑软件 SC_FEGAN）</p>
<h3 id="2-5-文本到图像生成"><a href="#2-5-文本到图像生成" class="headerlink" title="2.5 文本到图像生成"></a>2.5 文本到图像生成</h3><p>GAN 最惊人的成果之一，大概就是<a href="https://arxiv.org/abs/1711.10485" target="_blank" rel="external">根据文本生成图像</a>。用户提供一个句子，软件生成对应的图像。原始文本”一只红中透白、长着非常短的尖嘴的鸟”，可以得到下面的图像。</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102830.jpg" alt=""><br>（图24：根据文本生成图像）<br>论文甚至提到，将来存在可能，根据剧本直接生成一部电影。</p>
<h2 id="三、视频生成"><a href="#三、视频生成" class="headerlink" title="三、视频生成"></a>三、视频生成</h2><p>图像处理逐渐成熟以后，人工智能业界的关注重点就转向了视频。<br>从一个视频生成另一个视频，这就叫视频翻译。目前比较成熟的两个方向是运动传递和面部交换。</p>
<h3 id="3-1-运动传递"><a href="#3-1-运动传递" class="headerlink" title="3.1 运动传递"></a>3.1 运动传递</h3><p>运动传递指的是，将一个人的动作（包括身体、眼睛或嘴唇的动作）翻译到另一个人身上，使得另一个人出现一模一样的动作。<br>2018的论文<a href="https://carolineec.github.io/everybody_dance_now/" target="_blank" rel="external">《Everybody Dance Now》</a>，给出了一个模型，可以将舞者的动作移植到任何人身上。</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102831.jpg" alt=""><br>（图25：动作传递）<br>上图中，蓝衣女子的跳舞视频完全是假的，是将左上角舞者的动作套用在她身上，自动生成的。<br>NVIDIA 公司的开源软件 <a href="https://github.com/NVIDIA/vid2vid" target="_blank" rel="external">vid2vid</a> 更为强大，可以生成高分辨率的、连贯的逼真视频。</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102832.jpg" alt=""><br>（图26：vidvid 软件）</p>
<h3 id="3-2-脸部生成"><a href="#3-2-脸部生成" class="headerlink" title="3.2 脸部生成"></a>3.2 脸部生成</h3><p>脸部生成指的是，根据一张脸的表情和动作，重建另一张脸。最著名的例子是虚拟的<a href="http://grail.cs.washington.edu/projects/AudioToObama/" target="_blank" rel="external">奥巴马演讲</a>。2017年，华盛顿大学的团队发表了一段奥巴马的演讲视频。奥巴马其实从未做过这个演讲，是将别人的表情和口型套在他脸上生成的，语音也是合成的。</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102833.jpg" alt=""><br>（图27：虚拟的奥巴马演讲）<br>这种伪造的视频被称为 <a href="https://en.wikipedia.org/wiki/Deepfake" target="_blank" rel="external">Deepfake</a>（深度伪造），具有很大的欺骗性，许多在线平台都禁止上传这一类视频。</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102834.jpg" alt=""><br>（图28：伪造的特朗普演讲，将喜剧演员的表演变成特朗普自己在讲。）</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102837.jpg" alt=""><br>（图29：深度伪造的普京）<br>2018年出现的<a href="https://web.stanford.edu/~zollhoef/papers/SG2018_DeepVideo/page.html" target="_blank" rel="external">《深度视频肖像》</a>更进了一步，生成的视频不局限于虚拟的面部表情，还会头部旋转、眼睛凝视和眨眼，是 3D 的肖像重构。</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102835.jpg" alt=""><br>（图29：深度视频肖像）<br>这些技术还在<a href="https://www.theverge.com/2019/6/10/18659432/deepfake-ai-fakes-tech-edit-video-by-typing-new-words" target="_blank" rel="external">继续发展</a>，现在你可以给出任意文本，从任何你指定的对象嘴里说出来。甚至只凭一张照片，就可以生成一段表情变化的视频。</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102836.jpg" alt=""><br>（图30：一张照片生成各种表情）</p>
<h3 id="3-3-中国的实践"><a href="#3-3-中国的实践" class="headerlink" title="3.3 中国的实践"></a>3.3 中国的实践</h3><p>国内的人工智能视频生成，并不落后于国外。换脸应用 ZAO 只需用户上传一张照片，就能把影视剧主人公的脸换掉，好像你本人在表演电影一样。</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102838.jpg" alt=""><br>（图31：换脸应用 ZAO）<br>2018年，新华社与搜狗合作推出了虚拟新闻主播，具有真人的形象，带有声音、面部表情和动作，在电视上播报新闻，已经开通了英语、俄语、阿拉伯语的主持人。</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102839.jpg" alt=""><br>（图32：虚拟新闻主播）</p>
<h3 id="3-4-视频渲染"><a href="#3-4-视频渲染" class="headerlink" title="3.4 视频渲染"></a>3.4 视频渲染</h3><p>除了视频生成，人工智能在视频渲染上也取得了很大进展。<br>Nvidia 公司2018年展示了实时光线追踪 RTX 技术。这项技术用人工智能预测光线的变化，从而不用耗费大量计算去追踪光线，因此可以实时渲染出高画质的 3D 动画。这对于视频游戏有重大意义。<br>下面是使用这项技术的 Unreal Engine 4，实时渲染出的一个女子的<a href="https://venturebeat.com/2018/03/21/epic-games-shows-off-amazing-real-time-digital-human-with-siren-demo/" target="_blank" rel="external">3D 动画</a>，可以一边计算生成，一边播放，完全没有延迟。</p>
<p><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102840.jpg" alt=""><br><img src="https://www.wangbase.com/blogimg/asset/201910/bg2019102841.jpg" alt=""><br>（图32：实时渲染的动画）<br>实时光线追踪技术还可以用于自动驾驶，在白天和黑夜的不同时间，不同的路面和环境下，预测出暴雨、风雪和强烈的眩光导致的光线变化，对驾驶做出调整。</p>
<h2 id="四、文本和声音处理"><a href="#四、文本和声音处理" class="headerlink" title="四、文本和声音处理"></a>四、文本和声音处理</h2><p>最后，简单提一下，人工智能在文本和声音处理领域的进展。</p>
<h4 id="（1）语音合成"><a href="#（1）语音合成" class="headerlink" title="（1）语音合成"></a>（1）语音合成</h4><p>谷歌在2018年推出了智能助手 Google Duplex，它会根据你的日程，自动打电话去餐厅订座位。谷歌 CEO 说，这个机器人的对话能力，使得对方完全没有发现这是机器人。</p>
<h4 id="（2）音乐合成"><a href="#（2）音乐合成" class="headerlink" title="（2）音乐合成"></a>（2）音乐合成</h4><p>OpenAI 基金会推出的 <a href="https://openai.com/blog/musenet/" target="_blank" rel="external">MuseNet</a>，通过学习数十万段 MIDI 音乐，能做到使用10种乐器，生成一段4分钟的音乐。它的官网有这些音乐的下载，相当动听。</p>
<h4 id="（3）自动评论"><a href="#（3）自动评论" class="headerlink" title="（3）自动评论"></a>（3）自动评论</h4><p>据报道，使用 Yelp 网站的数据进行训练的模型，可以自动生成餐厅评论。</p>
<pre><code>- 我喜欢这个地方，一直来这里已经好多年。它是与朋友和家人相聚的好地点，我喜欢这里的食物和服务，从未有过糟糕的经历。
- 我吃了烤蔬菜汉堡配薯条！哦，很好吃！
- 我和我的家人都是这个地方的忠实粉丝。工作人员超级好，食物也很棒。鸡肉很好，大蒜酱也很完美。配水果的冰淇淋也很美味。强烈推荐！
- 上面这些都是机器生成的评论。
</code></pre><h4 id="（4）智能邮件"><a href="#（4）智能邮件" class="headerlink" title="（4）智能邮件"></a>（4）智能邮件</h4><p>Gmail 会根据电子邮件的来信内容，自动生成<a href="https://www.blog.google/products/gmail/save-time-with-smart-reply-in-gmail/" target="_blank" rel="external">三种不同的回复</a>，让用户选择。如果只是简单回应，用户不用自己动手写。<br>Gmail 的<a href="https://ai.googleblog.com/2018/05/smart-compose-using-neural-networks-to.html" target="_blank" rel="external">另一个功能</a>是，根据用户已经写的内容，预测接下来会写的句子，供用户选择。</p>
<h2 id="五、小结"><a href="#五、小结" class="headerlink" title="五、小结"></a>五、小结</h2><p>毫无疑问，人工智能是很酷的技术，创造出了神奇的产品，有着难以想象的巨大应用前景。<br>但是，人工智能也是一把双刃剑，模糊了现实与虚拟之间的界限，把我们带上了一条不可预测的道路。作为个人，了解这些技术的进展和潜力，有助于保持一份清醒，享受技术之福的同时，避免它带来的一些副作用。<br>（正文完）</p>
<hr>
<p>References</p>
<p>[1] 拍卖: <a href="https://www.christies.com/features/A-collaboration-between-two-artists-one-human-one-a-machine-9332-1.aspx" target="_blank" rel="external">https://www.christies.com/features/A-collaboration-between-two-artists-one-human-one-a-machine-9332-1.aspx</a><br>[2] 科普文章: <a href="https://blog.inten.to/welcome-to-the-simulation-dd0d8cb6534d" target="_blank" rel="external">https://blog.inten.to/welcome-to-the-simulation-dd0d8cb6534d</a><br>[3] 腾讯课堂: <a href="https://ke.qq.com/?utm=ruanyifeng" target="_blank" rel="external">https://ke.qq.com/?utm=ruanyifeng</a><br>[4] “腾讯课堂101计划”: <a href="https://edu.qq.com/a/20190119/005414.htm" target="_blank" rel="external">https://edu.qq.com/a/20190119/005414.htm</a><br>[5] 图像的对象补全模型: <a href="https://web.archive.org/web/20191016060740/http://iizuka.cs.tsukuba.ac.jp/projects/completion/en/" target="_blank" rel="external">https://web.archive.org/web/20191016060740/http://iizuka.cs.tsukuba.ac.jp/projects/completion/en/</a><br>[6] 它的网站: <a href="https://www.nvidia.com/research/inpainting/" target="_blank" rel="external">https://www.nvidia.com/research/inpainting/</a><br>[7] 图像软件: <a href="https://www.slashgear.com/adobes-entry-level-photoshop-elements-gets-new-ai-powered-tools-04594215/" target="_blank" rel="external">https://www.slashgear.com/adobes-entry-level-photoshop-elements-gets-new-ai-powered-tools-04594215/</a><br>[8] 很好的智能算法: <a href="https://towardsdatascience.com/background-removal-with-deep-learning-c4f2104b3157" target="_blank" rel="external">https://towardsdatascience.com/background-removal-with-deep-learning-c4f2104b3157</a><br>[9] 线上服务: <a href="https://www.remove.bg/" target="_blank" rel="external">https://www.remove.bg/</a><br>[10] 更改背景: <a href="https://arxiv.org/abs/1703.03872" target="_blank" rel="external">https://arxiv.org/abs/1703.03872</a><br>[11] 识别: <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf" target="_blank" rel="external">https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf</a><br>[12] 照片着色: <a href="https://arxiv.org/abs/1603.06668" target="_blank" rel="external">https://arxiv.org/abs/1603.06668</a><br>[13] 着色服务: <a href="https://colorize.cc/" target="_blank" rel="external">https://colorize.cc/</a><br>[14] 仓库: <a href="https://github.com/hindupuravinash/the-gan-zoo" target="_blank" rel="external">https://github.com/hindupuravinash/the-gan-zoo</a><br>[15] StyleGAN: <a href="https://arxiv.org/abs/1812.04948" target="_blank" rel="external">https://arxiv.org/abs/1812.04948</a><br>[16] 那个网站: <a href="http://www.whichfaceisreal.com/" target="_blank" rel="external">http://www.whichfaceisreal.com/</a><br>[17] BigGAN: <a href="https://arxiv.org/abs/1809.11096" target="_blank" rel="external">https://arxiv.org/abs/1809.11096</a><br>[18] pix2pix: <a href="https://github.com/phillipi/pix2pix" target="_blank" rel="external">https://github.com/phillipi/pix2pix</a><br>[19] CycleGAN: <a href="https://github.com/junyanz/CycleGAN" target="_blank" rel="external">https://github.com/junyanz/CycleGAN</a><br>[20] GauGAN: <a href="http://nvidia-research-mingyuliu.com/gaugan" target="_blank" rel="external">http://nvidia-research-mingyuliu.com/gaugan</a><br>[21] StarGAN: <a href="https://github.com/yunjey/StarGAN" target="_blank" rel="external">https://github.com/yunjey/StarGAN</a><br>[22] SC-FEGAN: <a href="https://github.com/run-youngjoo/SC-FEGAN" target="_blank" rel="external">https://github.com/run-youngjoo/SC-FEGAN</a><br>[23] 根据文本生成图像: <a href="https://arxiv.org/abs/1711.10485" target="_blank" rel="external">https://arxiv.org/abs/1711.10485</a><br>[24] 《Everybody Dance Now》: <a href="https://carolineec.github.io/everybody_dance_now/" target="_blank" rel="external">https://carolineec.github.io/everybody_dance_now/</a><br>[25] vid2vid: <a href="https://github.com/NVIDIA/vid2vid" target="_blank" rel="external">https://github.com/NVIDIA/vid2vid</a><br>[26] 奥巴马演讲: <a href="http://grail.cs.washington.edu/projects/AudioToObama/" target="_blank" rel="external">http://grail.cs.washington.edu/projects/AudioToObama/</a><br>[27] Deepfake: <a href="https://en.wikipedia.org/wiki/Deepfake" target="_blank" rel="external">https://en.wikipedia.org/wiki/Deepfake</a><br>[28] 《深度视频肖像》: <a href="https://web.stanford.edu/~zollhoef/papers/SG2018_DeepVideo/page.html" target="_blank" rel="external">https://web.stanford.edu/~zollhoef/papers/SG2018_DeepVideo/page.html</a><br>[29] 继续发展: <a href="https://www.theverge.com/2019/6/10/18659432/deepfake-ai-fakes-tech-edit-video-by-typing-new-words" target="_blank" rel="external">https://www.theverge.com/2019/6/10/18659432/deepfake-ai-fakes-tech-edit-video-by-typing-new-words</a><br>[30] 3D 动画: <a href="https://venturebeat.com/2018/03/21/epic-games-shows-off-amazing-real-time-digital-human-with-siren-demo/" target="_blank" rel="external">https://venturebeat.com/2018/03/21/epic-games-shows-off-amazing-real-time-digital-human-with-siren-demo/</a><br>[31] MuseNet: <a href="https://openai.com/blog/musenet/" target="_blank" rel="external">https://openai.com/blog/musenet/</a><br>[32] 自动生成: <a href="https://www.theverge.com/2017/8/31/16232180/ai-fake-reviews-yelp-amazon" target="_blank" rel="external">https://www.theverge.com/2017/8/31/16232180/ai-fake-reviews-yelp-amazon</a><br>[33] 三种不同的回复: <a href="https://www.blog.google/products/gmail/save-time-with-smart-reply-in-gmail/" target="_blank" rel="external">https://www.blog.google/products/gmail/save-time-with-smart-reply-in-gmail/</a><br>[34] 另一个功能: <a href="https://ai.googleblog.com/2018/05/smart-compose-using-neural-networks-to.html" target="_blank" rel="external">https://ai.googleblog.com/2018/05/smart-compose-using-neural-networks-to.html</a></p>
<hr>
<p>严重声明：本文转载自阮一峰的博客，版权属于原作者所有。<br><a href="http://www.ruanyifeng.com/blog/2019/10/artificial-intelligenence.html" target="_blank" rel="external">原文链接</a>。</p>

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/ai/" rel="tag">#AI</a>
          
            <a href="/tags/思考/" rel="tag">#思考</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/10/11/download-the-application-method-in-the-AppStore-of-overseas-region/" rel="next" title="下载海外地区的AppStore中应用的方法">
                <i class="fa fa-chevron-left"></i> 下载海外地区的AppStore中应用的方法
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      


    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.jpg"
               alt="isunman" />
          <p class="site-author-name" itemprop="name">isunman</p>
          <p class="site-description motion-element" itemprop="description">love IT, love Movie, love Love</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">64</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>
          
          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">10</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">39</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/isunman" target="_blank">
                  
                    <i class="fa fa-globe"></i> github
                  
                </a>
              </span>
            
          
        </div>

        
        

        <div class="links-of-author motion-element">
          
            <p class="site-author-name">Links</p>
            
              <span class="links-of-author-item">
                <a href="http://www.zhihu.com/" target="_blank">知乎</a>
              </span>
            
          
        </div>

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc-indicator-top post-toc-indicator">
            <i class="fa fa-angle-double-up"></i>
          </div>
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#一、图像处理"><span class="nav-number">1.</span> <span class="nav-text">一、图像处理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-对象补全"><span class="nav-number">1.1.</span> <span class="nav-text">1.1 对象补全</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-背景处理"><span class="nav-number">1.2.</span> <span class="nav-text">1.2 背景处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3-样式转换"><span class="nav-number">1.3.</span> <span class="nav-text">1.3 样式转换</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-4-图像着色"><span class="nav-number">1.4.</span> <span class="nav-text">1.4 图像着色</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#二、GAN-方法"><span class="nav-number">2.</span> <span class="nav-text">二、GAN 方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-简介"><span class="nav-number">2.1.</span> <span class="nav-text">2.1 简介</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-StyleGAN"><span class="nav-number">2.2.</span> <span class="nav-text">2.2 StyleGAN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-图像翻译"><span class="nav-number">2.3.</span> <span class="nav-text">2.3 图像翻译</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-人像翻译"><span class="nav-number">2.4.</span> <span class="nav-text">2.4 人像翻译</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-5-文本到图像生成"><span class="nav-number">2.5.</span> <span class="nav-text">2.5 文本到图像生成</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#三、视频生成"><span class="nav-number">3.</span> <span class="nav-text">三、视频生成</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-运动传递"><span class="nav-number">3.1.</span> <span class="nav-text">3.1 运动传递</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-脸部生成"><span class="nav-number">3.2.</span> <span class="nav-text">3.2 脸部生成</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-中国的实践"><span class="nav-number">3.3.</span> <span class="nav-text">3.3 中国的实践</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-4-视频渲染"><span class="nav-number">3.4.</span> <span class="nav-text">3.4 视频渲染</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#四、文本和声音处理"><span class="nav-number">4.</span> <span class="nav-text">四、文本和声音处理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#（1）语音合成"><span class="nav-number">4.0.1.</span> <span class="nav-text">（1）语音合成</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#（2）音乐合成"><span class="nav-number">4.0.2.</span> <span class="nav-text">（2）音乐合成</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#（3）自动评论"><span class="nav-number">4.0.3.</span> <span class="nav-text">（3）自动评论</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#（4）智能邮件"><span class="nav-number">4.0.4.</span> <span class="nav-text">（4）智能邮件</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#五、小结"><span class="nav-number">5.</span> <span class="nav-text">五、小结</span></a></li></ol></div>
            
          </div>
          <div class="post-toc-indicator-bottom post-toc-indicator">
            <i class="fa fa-angle-double-down"></i>
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
<div class="copyright" >
  
  &copy;  2011 - 
  <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">isunman</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="powered-by">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>
<div class="theme-info">
<span id="busuanzi_container_site_pv">
    PV<span id="busuanzi_value_site_pv"></span> --
</span>
<span id="busuanzi_container_site_uv">
  UV<span id="busuanzi_value_site_uv"></span>
</span>
</div>


      </div>
    </footer>

    <div class="back-to-top"></div>
  </div>

  


  



  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  <script type="text/javascript" src="/vendors/velocity/velocity.min.js"></script>

  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js"></script>

  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=0.5.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=0.5.0"></script>



  
  

  
  
<script type="text/javascript" src="/js/src/scrollspy.js?v=0.5.0"></script>

<script type="text/javascript" id="sidebar.toc.highlight">
  $(document).ready(function () {
    var tocSelector = '.post-toc';
    var $tocSelector = $(tocSelector);
    var activeCurrentSelector = '.active-current';

    $tocSelector
      .on('activate.bs.scrollspy', function () {
        var $currentActiveElement = $(tocSelector + ' .active').last();

        removeCurrentActiveClass();
        $currentActiveElement.addClass('active-current');

        $tocSelector[0].scrollTop = $currentActiveElement.position().top;
      })
      .on('clear.bs.scrollspy', function () {
        removeCurrentActiveClass();
      });

    function removeCurrentActiveClass () {
      $(tocSelector + ' ' + activeCurrentSelector)
        .removeClass(activeCurrentSelector.substring(1));
    }

    function processTOC () {
      getTOCMaxHeight();
      toggleTOCOverflowIndicators();
    }

    function getTOCMaxHeight () {
      var height = $('.sidebar').height() -
                   $tocSelector.position().top -
                   $('.post-toc-indicator-bottom').height();

      $tocSelector.css('height', height);

      return height;
    }

    function toggleTOCOverflowIndicators () {
      tocOverflowIndicator(
        '.post-toc-indicator-top',
        $tocSelector.scrollTop() > 0 ? 'show' : 'hide'
      );

      tocOverflowIndicator(
        '.post-toc-indicator-bottom',
        $tocSelector.scrollTop() >= $tocSelector.find('ol').height() - $tocSelector.height() ? 'hide' : 'show'
      )
    }

    $(document).on('sidebar.motion.complete', function () {
      processTOC();
    });

    $('body').scrollspy({ target: tocSelector });
    $(window).on('resize', function () {
      if ( $('.sidebar').hasClass('sidebar-active') ) {
        processTOC();
      }
    });

    onScroll($tocSelector);

    function onScroll (element) {
      element.on('mousewheel DOMMouseScroll', function (event) {
          var oe = event.originalEvent;
          var delta = oe.wheelDelta || -oe.detail;

          this.scrollTop += ( delta < 0 ? 1 : -1 ) * 30;
          event.preventDefault();

          toggleTOCOverflowIndicators();
      });
    }

    function tocOverflowIndicator (indicator, action) {
      var $indicator = $(indicator);
      var opacity = action === 'show' ? 1 : 0;
      $indicator.velocity ?
        $indicator.velocity('stop').velocity({
          opacity: opacity
        }, { duration: 100 }) :
        $indicator.stop().animate({
          opacity: opacity
        }, 100);
    }

  });
</script>

<script type="text/javascript" id="sidebar.nav">
  $(document).ready(function () {
    var html = $('html');
    var TAB_ANIMATE_DURATION = 200;
    var hasVelocity = $.isFunction(html.velocity);

    $('.sidebar-nav li').on('click', function () {
      var item = $(this);
      var activeTabClassName = 'sidebar-nav-active';
      var activePanelClassName = 'sidebar-panel-active';
      if (item.hasClass(activeTabClassName)) {
        return;
      }

      var currentTarget = $('.' + activePanelClassName);
      var target = $('.' + item.data('target'));

      hasVelocity ?
        currentTarget.velocity('transition.slideUpOut', TAB_ANIMATE_DURATION, function () {
          target
            .velocity('stop')
            .velocity('transition.slideDownIn', TAB_ANIMATE_DURATION)
            .addClass(activePanelClassName);
        }) :
        currentTarget.animate({ opacity: 0 }, TAB_ANIMATE_DURATION, function () {
          currentTarget.hide();
          target
            .stop()
            .css({'opacity': 0, 'display': 'block'})
            .animate({ opacity: 1 }, TAB_ANIMATE_DURATION, function () {
              currentTarget.removeClass(activePanelClassName);
              target.addClass(activePanelClassName);
            });
        });

      item.siblings().removeClass(activeTabClassName);
      item.addClass(activeTabClassName);
    });

    $('.post-toc a').on('click', function (e) {
      e.preventDefault();
      var targetSelector = NexT.utils.escapeSelector(this.getAttribute('href'));
      var offset = $(targetSelector).offset().top;
      hasVelocity ?
        html.velocity('stop').velocity('scroll', {
          offset: offset  + 'px',
          mobileHA: false
        }) :
        $('html, body').stop().animate({
          scrollTop: offset
        }, 500);
    });

    // Expand sidebar on post detail page by default, when post has a toc.
    NexT.motion.middleWares.sidebar = function () {
      var $tocContent = $('.post-toc-content');

      if (CONFIG.sidebar.display === 'post' || CONFIG.sidebar.display === 'always') {
        if ($tocContent.length > 0 && $tocContent.html().trim().length > 0) {
          NexT.utils.displaySidebar();
        }
      }
    };
  });
</script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=0.5.0"></script>



  



  



  
  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>

  
    <script type="text/javascript" src="http://cdn.staticfile.org/mathjax/2.4.0/MathJax.js"></script>
    <script type="text/javascript" src="http://cdn.staticfile.org/mathjax/2.4.0/config/TeX-AMS-MML_HTMLorMML.js"></script>
  


  
  


  

</body>
</html>
